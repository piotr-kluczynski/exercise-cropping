{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f4d4a7f-1f88-472e-9554-a475c539df06",
   "metadata": {},
   "source": [
    "#### Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149ad31-600d-486d-ab1a-b15b28b0e128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "!pip install numpy\n",
    "!pip install pydantic\n",
    "!pip install langgraph\n",
    "!pip install langchain-community\n",
    "!pip install langchain-anthropic\n",
    "!pip install langgraph-checkpoint-sqlite\n",
    "!pip install langchain[openai]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeafaf0-8145-47c7-874c-d4c47906d32d",
   "metadata": {},
   "source": [
    "#### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86f4fa-d74e-492e-a69d-2f8c54ef7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import base64\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ac4b22-cf51-40c8-a4fe-7f21ba2dd8f8",
   "metadata": {},
   "source": [
    "#### Setting up environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd460797-ba22-48aa-affc-7f41fffaaad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c5bb25-7827-42ff-92c2-1632ae5874ea",
   "metadata": {},
   "source": [
    "#### Loading and adjusting the image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769fde3d-9630-4f6c-99ac-5291b3c9741f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(\"example.jpg\")\n",
    "height, width, _ = image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aebb6d7-831a-4743-8d5d-ba6a3204d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_height = ((height // 32) + 1) * 32 \n",
    "new_width = ((width // 32) + 1) * 32 \n",
    "\n",
    "image_resized = cv.resize(image, (new_width, new_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00023b6-51c0-43d3-b6fc-6d1c5a4c18c2",
   "metadata": {},
   "source": [
    "#### Detecting text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1dbc6a-9696-4400-985d-80d4897df024",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_r, mean_g, mean_b, _ = cv.mean(image_resized)\n",
    "mean = (mean_r, mean_g, mean_b)\n",
    "\n",
    "bin_threshold = 0.3\n",
    "poly_threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60035d52-76e8-4ab9-815c-e3b5dee6eb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "textDetectorDB50 = cv.dnn_TextDetectionModel_DB(\"DB_TD500_resnet50.onnx\")\n",
    "textDetectorDB50.setBinaryThreshold(bin_threshold)\n",
    "textDetectorDB50.setPolygonThreshold(poly_threshold)\n",
    "textDetectorDB50.setInputParams(1.0/255, (new_width, new_height), mean, True)\n",
    "\n",
    "boxes, confidences = textDetectorDB50.detect(image_resized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593bd6be-9c55-4253-9438-af5fddc98213",
   "metadata": {},
   "source": [
    "#### Preparing mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6feda1-5ccf-428e-8cef-ae8389f85c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpaint_mask_db50 = np.zeros(image_resized.shape[:2], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f8a644-9df6-4932-94f0-192d8286028e",
   "metadata": {},
   "source": [
    "#### Merging close boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38958f-517c-4303-af19-c3a6eb2d939a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxes_distance(A_min, A_max, B_min, B_max):\n",
    "    delta1 = A_min - B_max\n",
    "    delta2 = B_min - A_max\n",
    "    \n",
    "    u = np.max(np.array([np.zeros(len(delta1)), delta1]), axis=0)\n",
    "    v = np.max(np.array([np.zeros(len(delta2)), delta2]), axis=0)\n",
    "    \n",
    "    dist = np.linalg.norm(np.concatenate([u, v]))\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079068a4-b409-45e9-9e1e-8d63ff069a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_boxes(A_box, B_box):\n",
    "    C_0 = [min(A_box[0][0], B_box[0][0]), max(A_box[0][1], B_box[0][1])] # Top-right point\n",
    "    C_1 = [min(A_box[1][0], B_box[1][0]), min(A_box[1][1], B_box[1][1])] # Top-left point\n",
    "    C_2 = [max(A_box[2][0], B_box[2][0]), min(A_box[2][1], B_box[2][1])] # Bottom-left point\n",
    "    C_3 = [max(A_box[3][0], B_box[3][0]), max(A_box[3][1], B_box[3][1])] # Bottom-right point \n",
    "\n",
    "    \n",
    "    return np.array([C_0, C_1, C_2, C_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a140973e-0363-40f0-9368-154201f12cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_distance = 10\n",
    "boxes_refined = [box for box in boxes]\n",
    "\n",
    "i = 0\n",
    "while i < len(boxes_refined):\n",
    "    j = i + 1\n",
    "    merged = False\n",
    "\n",
    "    A_min = boxes_refined[i][1]\n",
    "    A_max = boxes_refined[i][3]\n",
    "\n",
    "    while j < len(boxes_refined):\n",
    "        B_min = boxes_refined[j][1]\n",
    "        B_max = boxes_refined[j][3]\n",
    "\n",
    "        distance = boxes_distance(A_min, A_max, B_min, B_max)\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            boxes_refined[i] = merge_boxes(boxes_refined[i], boxes_refined[j])\n",
    "            boxes_refined.pop(j)\n",
    "            \n",
    "            merged = True\n",
    "        else:\n",
    "            j += 1\n",
    "    if not merged:\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6a62e1-064d-4950-b93c-00ff9e30a80d",
   "metadata": {},
   "source": [
    "#### Highlighting boxes on the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3719a46-16fd-4e22-bb08-da82a0537e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_refined_boxes = image_resized.copy()\n",
    "\n",
    "color = (255, 0, 0)\n",
    "thickness = 2\n",
    "\n",
    "for box in boxes_refined:\n",
    "    cv.fillPoly(inpaint_mask_db50, [np.array(box, np.int32)], 255)\n",
    "    cv.polylines(image_refined_boxes, [np.array(box, np.int32)], isClosed=True, color=color, thickness=thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a671d4cf-212b-400a-887b-403a05645d97",
   "metadata": {},
   "source": [
    "#### Assigning a number to each box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb3452-e454-4339-ac5d-f7a0c1308850",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_numbered = image_refined_boxes.copy()\n",
    "\n",
    "color = (0, 0, 255)\n",
    "thickness = 2\n",
    "font = cv.FONT_HERSHEY_SIMPLEX\n",
    "font_scale = 0.5\n",
    "\n",
    "x_offset = -10\n",
    "y_offset = -5\n",
    "\n",
    "for i in range(len(boxes_refined)):\n",
    "    cv.putText(image_numbered, str(i), (boxes_refined[i][1][0] + x_offset, boxes_refined[i][1][1] + y_offset), font, font_scale, color, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f2fe45-7915-4a5b-ac2b-c88739d86ce8",
   "metadata": {},
   "source": [
    "#### Creating the output structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7476f0c-cd18-4459-8dd3-42490582fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class boxes_list(BaseModel):\n",
    "    boxes_ids: list[int] = Field(description=\"The ids of text boxes containing the exercise descriptions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be5b11-871c-4c4e-ac33-173bc3dd581f",
   "metadata": {},
   "source": [
    "#### Creating an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ed4a3c-5cf7-477f-8a74-22c3300a594c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "structured_model = model.with_structured_output(boxes_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edf86bf-95ba-40fc-98a9-f14716dd7b25",
   "metadata": {},
   "source": [
    "#### Calling the agent to choose boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd4207-a744-4850-8317-25d36c2cee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, buffer = cv.imencode(\".jpg\", image_numbered)\n",
    "image_bytes = buffer.tobytes()\n",
    "image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b0cf3-9e92-4925-8c41-e242f72fa4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = SystemMessage(content = \"You will be provided with an image of the page from the textbook for learning Luxembourgish.\\\n",
    "                                          The text on the image will be highlighted by the boxes and assigned a number.\\\n",
    "                                          Your task is to return the numbers of those boxes, which contain the exercise for the student.\\\n",
    "                                          Each exercise follow a specific convention - they start from an exercise number, followed by description.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4340f508-1aef-48f1-b81f-cb11341b4b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message = HumanMessage(content = [{\n",
    "                                    \"type\": \"image\", \"source_type\": \"base64\",\n",
    "                                     \"mime_type\": \"image/jpeg\", \"data\": image_base64\n",
    "                                }]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae917b0-00f3-4a8d-8351-efc786a3358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "response = structured_model.invoke([\n",
    "    system_message,\n",
    "    user_message\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a17135-e3b9-457b-a1fb-3bec1e813b03",
   "metadata": {},
   "source": [
    "#### Cropping the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17d9c0-3f5c-4423-84d3-b03b1cbdd929",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_images = []\n",
    "\n",
    "initial_offset = 10\n",
    "\n",
    "boxes_ids = response.boxes_ids.copy()\n",
    "\n",
    "for i in range(len(boxes_ids)):\n",
    "    upper_bound = boxes_refined[boxes_ids[i]][1][1]\n",
    "    \n",
    "    if (upper_bound - initial_offset) > 0:\n",
    "        upper_bound -= initial_offset\n",
    "        \n",
    "    if i == len(boxes_ids) - 1:\n",
    "        lower_bound = new_height\n",
    "    else:\n",
    "        lower_bound = boxes_refined[boxes_ids[i + 1]][1][1]\n",
    "\n",
    "    cropped_image = image_resized[upper_bound:lower_bound, 0:new_width]\n",
    "    \n",
    "    cropped_images.append(cropped_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61143ec-0688-42e2-9391-ad3d196eadb3",
   "metadata": {},
   "source": [
    "#### Adjusting the cropped images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559ea5e5-0835-41b3-9c89-97f605e792f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "left_offset = 15\n",
    "right_offset = 40\n",
    "top_offset = 0\n",
    "bottom_offset = 10\n",
    "\n",
    "for i in range(len(cropped_images)):\n",
    "    cropped_height, cropped_width, _ = cropped_images[i].shape\n",
    "    cropped_images[i] = cropped_images[i][0 + top_offset: cropped_height - bottom_offset, 0 + left_offset:cropped_width - right_offset]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f572a85-a256-44ab-9556-c6d608f80e3d",
   "metadata": {},
   "source": [
    "#### Saving the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc91f58-2cea-420b-8a31-159051b7e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cropped_images)):\n",
    "    cv.imwrite(f\"cropped_images/cropped_image_{i}.jpg\", cropped_images[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
